{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 由文本到词向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用到的库\n",
    "import jieba        #分词\n",
    "import jieba.analyse\n",
    "\n",
    "from gensim.models import word2vec  #训练词向量\n",
    "\n",
    "import logging\n",
    "import os\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 新闻文本预处理\n",
    "使用正则表达式去除非文本部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#一部分已用停用词完成去除\n",
    "#暂时跳过这一步，不熟悉正则表达式:（\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分词处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#新闻来源词频修改\n",
    "jieba.suggest_freq('上海证券报', True)\n",
    "jieba.suggest_freq('华夏时报', True)\n",
    "jieba.suggest_freq('券商中国', True)\n",
    "jieba.suggest_freq('国际金融报', True)\n",
    "jieba.suggest_freq('经济观察网', True)\n",
    "jieba.suggest_freq('第一财经', True)\n",
    "jieba.suggest_freq('全景财经', True)\n",
    "jieba.suggest_freq('中国基金报', True)\n",
    "jieba.suggest_freq('深圳商报', True)\n",
    "#...待补充\n",
    "\n",
    "# 导入停用词表\n",
    "#从文件导入停用词表\n",
    "stpwrdpath = \"./data/stop_words.txt\"\n",
    "stpwrd_dic = open(stpwrdpath, 'r', encoding='utf-8')\n",
    "stpwrd_content = stpwrd_dic.read()\n",
    "#将停用词表转换为list  \n",
    "stpwrdlst = stpwrd_content.splitlines()\n",
    "stpwrd_dic.close()\n",
    "\n",
    "\n",
    "with open('./data/east_money_news.txt',encoding='utf-8') as f:\n",
    "    # 读入原始新闻文本\n",
    "    document = f.read()\n",
    "    # 分词后去除列表中的停用词\n",
    "    document_cut=[]\n",
    "    document_cut += [word for word in jieba.cut(document) if word not in stpwrdlst]\n",
    "    # 用空格分隔分词结果，形成分词后文本\n",
    "    result = ' '.join(document_cut)\n",
    "    \n",
    "    with open('./data/east_money_news01.txt', 'w', encoding='utf-8') as f2:\n",
    "        f2.write(result)\n",
    "f.close()\n",
    "f2.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## word2vec模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-10-25 16:32:32,506 : INFO : collecting all words and their counts\n",
      "2020-10-25 16:32:32,513 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-10-25 16:32:32,566 : INFO : collected 19371 word types from a corpus of 126203 raw words and 2090 sentences\n",
      "2020-10-25 16:32:32,567 : INFO : Loading a fresh vocabulary\n",
      "2020-10-25 16:32:32,643 : INFO : effective_min_count=1 retains 19371 unique words (100% of original 19371, drops 0)\n",
      "2020-10-25 16:32:32,643 : INFO : effective_min_count=1 leaves 126203 word corpus (100% of original 126203, drops 0)\n",
      "2020-10-25 16:32:32,696 : INFO : deleting the raw counts dictionary of 19371 items\n",
      "2020-10-25 16:32:32,697 : INFO : sample=0.001 downsamples 18 most-common words\n",
      "2020-10-25 16:32:32,698 : INFO : downsampling leaves estimated 115141 word corpus (91.2% of prior 126203)\n",
      "2020-10-25 16:32:32,715 : INFO : constructing a huffman tree from 19371 words\n",
      "2020-10-25 16:32:33,150 : INFO : built huffman tree with maximum node depth 17\n",
      "2020-10-25 16:32:33,180 : INFO : estimated required memory for 19371 words and 100 dimensions: 36804900 bytes\n",
      "2020-10-25 16:32:33,181 : INFO : resetting layer weights\n",
      "2020-10-25 16:32:36,916 : INFO : training model with 3 workers on 19371 vocabulary and 100 features, using sg=0 hs=1 sample=0.001 negative=5 window=3\n",
      "2020-10-25 16:32:37,103 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-10-25 16:32:37,116 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-10-25 16:32:37,123 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-10-25 16:32:37,124 : INFO : EPOCH - 1 : training on 126203 raw words (115123 effective words) took 0.2s, 562473 effective words/s\n",
      "2020-10-25 16:32:37,312 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-10-25 16:32:37,313 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-10-25 16:32:37,317 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-10-25 16:32:37,317 : INFO : EPOCH - 2 : training on 126203 raw words (115079 effective words) took 0.2s, 599887 effective words/s\n",
      "2020-10-25 16:32:37,497 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-10-25 16:32:37,504 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-10-25 16:32:37,519 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-10-25 16:32:37,520 : INFO : EPOCH - 3 : training on 126203 raw words (115103 effective words) took 0.2s, 576369 effective words/s\n",
      "2020-10-25 16:32:37,714 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-10-25 16:32:37,721 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-10-25 16:32:37,722 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-10-25 16:32:37,722 : INFO : EPOCH - 4 : training on 126203 raw words (115102 effective words) took 0.2s, 576714 effective words/s\n",
      "2020-10-25 16:32:37,917 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-10-25 16:32:37,922 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-10-25 16:32:37,925 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-10-25 16:32:37,927 : INFO : EPOCH - 5 : training on 126203 raw words (115154 effective words) took 0.2s, 571109 effective words/s\n",
      "2020-10-25 16:32:37,928 : INFO : training on a 631015 raw words (575561 effective words) took 1.0s, 569524 effective words/s\n"
     ]
    }
   ],
   "source": [
    "# 开启日志记录\n",
    "logging.basicConfig(format=\n",
    "                    '%(asctime)s : %(levelname)s : %(message)s'\n",
    "                    , level=logging.INFO)\n",
    "\n",
    "# 使用 word2vec 提供的 LineSentence 类来读文件\n",
    "sentences = word2vec.LineSentence(\n",
    "    './data/east_money_news01.txt'\n",
    ") \n",
    "\n",
    "# 建立模型 （ 暂时使用了默认参数 ）\n",
    "model = word2vec.Word2Vec(\n",
    "    sentences, hs=1,min_count=1,window=3,size=100\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型查看与简单应用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "重磅\n",
      "央行\n",
      "行长\n",
      "易纲\n",
      "最新\n",
      "讲话\n",
      "金融业\n",
      "开放\n",
      "汇率\n",
      "释放\n",
      "信号\n",
      "24\n",
      "举行\n",
      "外滩\n",
      "金融\n",
      "峰会\n",
      "中国人民银行\n",
      "表示\n",
      "我国\n",
      "持续\n",
      "推动\n",
      "营造\n",
      "市场化\n",
      "法治化\n",
      "国际化\n",
      "展业\n",
      "环境\n",
      "人民币\n",
      "形成\n",
      "机制\n",
      "改革\n",
      "增强\n",
      "弹性\n",
      "10\n",
      "25\n",
      "00\n",
      "03\n",
      "周末\n",
      "要闻\n",
      "汇总\n",
      "证监会\n",
      "沪\n",
      "深\n",
      "交易所\n",
      "联合\n",
      "围剿\n",
      "剑\n",
      "指\n",
      "可转债\n",
      "疯狂\n",
      "炒作\n",
      "王岐山\n",
      "中国\n",
      "走\n",
      "投机\n",
      "赌博\n",
      "歪路\n",
      "庞氏\n",
      "骗局\n",
      "邪路\n",
      "马云\n",
      "已\n",
      "完成\n",
      "蚂蚁\n",
      "集团\n",
      "上市\n",
      "定价\n",
      "13\n",
      "51\n",
      "贵州\n",
      "茅台\n",
      "三季度\n",
      "净利润\n",
      "同比\n",
      "增长\n",
      "11%\n",
      "日晚\n",
      "披露\n",
      "季报\n",
      "公司\n",
      "营收\n",
      "672.14\n",
      "亿元\n",
      "10.31%\n",
      "338.27\n",
      "11.07%\n",
      "e\n",
      "14\n",
      "07\n",
      "机构\n",
      "买\n",
      "明星\n",
      "基金\n",
      "经理\n",
      "操作\n",
      "曝光\n",
      "无效\n",
      "仓位\n",
      "正在\n",
      "甩卖\n"
     ]
    }
   ],
   "source": [
    "# 打印模型中词频最高的前 100 个词\n",
    "for i, word in enumerate(model.wv.vocab):\n",
    "    if i == 100:\n",
    "        break\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "阿里巴巴 0.928087055683136\n",
      "世茂 0.8994611501693726\n",
      "连促 0.8847653269767761\n",
      "根据上述 0.8813643455505371\n",
      "肯定 0.8812633752822876\n",
      "礼德 0.8782703876495361\n",
      "科创板 0.8689405918121338\n",
      "流入 0.8666212558746338\n",
      "终身免疫 0.8656302690505981\n",
      "绿色生态 0.8647975921630859\n",
      "实质性 0.864722490310669\n",
      "上汽 0.864434003829956\n",
      "马云 0.8622527718544006\n",
      "数字 0.8617914915084839\n",
      "大热 0.8615632057189941\n",
      "陶冉摄 0.8612689971923828\n",
      "华晨 0.8608403205871582\n",
      "透露 0.8559889793395996\n",
      "民天 0.8547335267066956\n",
      "不小 0.8546103239059448\n",
      "告诉 0.8525744676589966\n",
      "受害人 0.847034215927124\n",
      "城东 0.844398021697998\n",
      "嘉友 0.8443098068237305\n",
      "港 0.8423876762390137\n",
      "忘记 0.840843677520752\n",
      "境内 0.840360164642334\n",
      "A轮 0.8373105525970459\n",
      "推行 0.8371132612228394\n",
      "外衣 0.8368769884109497\n"
     ]
    }
   ],
   "source": [
    "#通过词向量，找出与目标词关系最近的前 20 个词\n",
    "for key in model.wv.similar_by_word('蚂蚁', topn =30):\n",
    "        print(key[0], key[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
